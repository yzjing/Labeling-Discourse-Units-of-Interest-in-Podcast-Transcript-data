\section{Introduction} \label{sec:introduction}


% Text segmentation (TS) is a fundamental task in natural language processing (NLP). 

Understanding discourse structure is a fundamental problem in traditional linguistics, but is less studied in natural language processing (NLP). Signaled by syntactic, semantic, and prosodic features, discourse structure is what enables discourse to be ``more than a sequence of sentences" \cite{webber2009discourse}. Identifying discourse structure is key to understanding many aspects of human communication, such as pragmatic language usage \cite{redeker1990ideational}, cultural differences \cite{clyne1981culture}, and social activities in general. Many computational theories and studies of discourse structure focus on detailed phrasal elements, providing a foundation for understanding implicature, scope, reference, inference, and other logical relationships \cite{polanyi1996linguistic, grosz1986attention, asher2003logics}, with application on specific tasks such as argument detection \cite{mochales2011argumentation} and dialogue generation \cite{hovy1993automated}. Meanwhile, although a few theories include extra-sentential levels of structure \cite{mann1988rhetorical}, the automatic identification of macro-level discourse structure remains an open problem.

 A trove of computationally accessible voice recordings has become available in recent years in the form of podcasts and recorded digital radio programs (e.g. see \citet{beeferman2019radiotalk}). These recordings provide an invaluable resource for the linguistic study of spoken discourse, which is normally an ephemeral process. 
 
 Here we leverage this resource to build a model of discourse structure at a higher level. As a first step, we start with identifying the part of a text that serves as an introduction or summarization. Specifically, we work on two tasks: the first is to segment the abstracts of academic papers from the body texts. Although the abstract and body of a paper usually discuss the same topics and share a vocabulary, the different styles and functions in the paper set them apart. We use this task as a proof-of-concept that our methods are able to recognize structural features in addition to topical or lexical ones. We then apply our methods to extract the introductions of podcasts from their transcripts. Introductions in podcasts typically describe the episodes' main subject(s), contents, and speakers. Listening to a podcast episode's introduction can often stimulate listeners' interest and help them decide whether to listen to the whole episode. This gives our task applied value in addition to theoretical value.
 
%  It has also been shown that functional words, which often signals discourse structure, reveal important aspects of human behaviour \cite{chung2007psychological}.
 
We perform the paper abstract segmentation task on a dataset of NeurIPS papers published on Kaggle \cite{nipsdata} (referred as ``NeurIPS task" hereafter). A dataset of labeled podcast transcripts is created for the podcast introduction extraction task (the ``Podcast task").  After obtaining transcripts using automatic speech recognition (ASR) tools, we recruited lightly-trained volunteers to annotate the introductions, obtaining labeled data for 417 podcast episodes. We explore the annotator agreement, showing that human annotators achieve reasonable agreement on the locations and components of introductions. For the details, see Section~\ref{sec:data}.\footnote{The dataset and code that we create will be made public.}

We explore several strategies for extracting text based on discourse structure. We formulate each task as a supervised sequence labeling task. Inspired by a previous approach \cite{salloum2017automated}, we train our models to label each token in the text, and find the best split position based on the token labels. To highlight the difference between the structure and contents of text data, we create a baseline model using only lexical features (word embeddings). We then experiment with the state-of-the-art NLP models, including recurrent neural networks (RNNs) and transformer models, where we train a traditional bi-directional long short-term memory (Bi-LSTM) model and fine-tune a pre-trained BERT model \cite{devlin2018bert} using our labeled data. We evaluate the models using two metrics: the accuracy of identifying the segmentation boundaries (\emph{accuracy}), and the overlap between the predicted introduction and the gold standard (\emph{overlap score}). 

We find that both the Bi-LSTM and the fine-tuned BERT model perform very well in the NeurIPS task, reaching an accuracy of over 99\% and outperform our lexical baseline by over 20\%. This demonstrates our models' ability in segmenting text based on structure. In the more difficult Podcast task, the fine-tuned BERT performs best, reaching an accuracy of 41\% at offset $=$ 3 and average overlap score of 0.526 when testing on material that is structurally similar with the training data, and 17.9\% average accuracy at offset $=$ 3 and average overlap score of 0.156 when testing on data that is structurally different from the training data (see Section \ref{sec:results}). We further analyze the attention weights and learned hidden representations in the fine-tuned BERT model, demonstrating that it is able to learn structural information in additional to topical or lexical cues.

% Structural TS is important in more than one ways: it may allow us to extract functionally meaningful blocks of text, such as the summary or conclusion of a long article. It may also enable us to identify structure changes in narrative documents, such as the transition between acts in a movie script. While the potential application of structural TS is wide,